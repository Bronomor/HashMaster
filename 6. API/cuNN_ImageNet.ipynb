{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12d400e8-a290-4fdf-bd0b-cf08984a6d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import _pickle as cPickle\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "\n",
    "torch.set_default_device('cpu') \n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "IMAGENET_PATH = \"../data/Imagenet32_train/\"\n",
    "PATH = \"../2.NeuralHashing/mainModel.pth\"\n",
    "HASH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dc06768-b862-4546-b29e-90ee790b4dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = cPickle.load(fo)\n",
    "    return dict\n",
    "\n",
    "def load_databatch(data_folder, idx, img_size=32):\n",
    "    data_file = os.path.join(data_folder, 'train_data_batch_')\n",
    "\n",
    "    dict_ = unpickle(data_file + str(idx))\n",
    "\n",
    "    images = dict_['data']\n",
    "    labels = dict_['labels']\n",
    "\n",
    "    ## images_without_mean = dict_['mean']   ??? check is there are better results or not\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15876c35-6c5d-4a30-9492-1757d9466190",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_databatch(IMAGENET_PATH, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e29bac35-c72f-4d75-ad29-e51688d8adf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of images: 128116\n"
     ]
    }
   ],
   "source": [
    "print( \"size of images:\", len(labels) )\n",
    "images = images.astype(np.float32).reshape(128116,3,32,32)\n",
    "dataset = CustomDataset(torch.from_numpy(images), torch.Tensor(labels) )\n",
    "ImageNetLoader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6395beb4-dc6c-42f0-bd90-db692db4aa9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor(1000.),\n",
       "indices=tensor(392))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max( torch.Tensor(labels) , 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de9504a-5d47-4872-ab85-567709eaa3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8402e38-e0f7-4172-823d-80638ff131ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, bits):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2048, 1000)\n",
    "        self.hash1 = nn.Linear(1000, 64)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(1000, 1000)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float32)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.sigmoid(x)\n",
    "        hash_ = self.hash1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = x.softmax(1)\n",
    "        return x, hash_\n",
    "\n",
    "net = Net( HASH_SIZE )\n",
    "net.to(device)\n",
    "\n",
    "resnet50 = models.resnet50(pretrained = True) # weights=ResNet50_Weights.DEFAULT\n",
    "resnet50 = resnet50.to(device)\n",
    "resnet50.fc = torch.nn.Identity()\n",
    "\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in resnet50.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "for param in resnet50.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model = nn.Sequential(resnet50, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2386c105-9155-420c-ad86-defac3771658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load(PATH))\n",
    "model = model.to(device)\n",
    "\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "optimizer2 = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "iterations = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30ecf7dc-af77-4127-a07c-742474ad4a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py:78: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "1  tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/cuda/ScatterGatherKernel.cu:365: operator(): block: [0,0,0], thread: [10,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m labels_one_hot \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mone_hot( labels\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mint64), \u001b[38;5;241m1000\u001b[39m )\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)  \n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion2(outputs\u001b[38;5;241m.\u001b[39mto(device), labels_one_hot\u001b[38;5;241m.\u001b[39mto(device))        \n\u001b[0;32m---> 16\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m optimizer2\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     19\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:516\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradient of current tensor wrt graph leaves.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03mThe graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;124;03m        used to compute the attr::tensors.\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    527\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/overrides.py:1619\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_function_mode_enabled():\n\u001b[1;32m   1616\u001b[0m     \u001b[38;5;66;03m# if we're here, the mode must be set to a TorchFunctionStackMode\u001b[39;00m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;66;03m# this unsets it and calls directly into TorchFunctionStackMode's torch function\u001b[39;00m\n\u001b[1;32m   1618\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _pop_mode_temporarily() \u001b[38;5;28;01mas\u001b[39;00m mode:\n\u001b[0;32m-> 1619\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mmode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1620\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1621\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py:78\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range( 10 ):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, data in enumerate(ImageNetLoader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer2.zero_grad()\n",
    "        outputs, hash_ = model(inputs)\n",
    "\n",
    "        print( torch.max(outputs) )\n",
    "\n",
    "        #outputs = outputs.type(torch.int64)\n",
    "        labels_one_hot = torch.nn.functional.one_hot( labels.type(torch.int64), 1000 ).to(torch.float32)  \n",
    "        loss = criterion2(outputs.to(device), labels_one_hot.to(device))        \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer2.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 0:\n",
    "            print(i + 1, \" \", end=\"\")\n",
    "            \n",
    "        total += labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted.to(device) == labels.to(device)).sum().item()\n",
    "\n",
    "    print(f'[{epoch + 1}] loss: {running_loss} accurancy: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e817054e-4207-462c-a5b3-13afc14aefb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in ImageNetLoader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs, _ = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b68c30-206d-4edb-9358-aabfe6df845d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e825d54b-b7bb-4a78-a0f5-79cd00e29f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
